from sklearn.linear_model import LinearRegression
import numpy as np
from sklearn.metrics import mean_absolute_error, mean_squared_error

# Generar datos de entrenamiento falsos
X = np.array([
    [-4,-0.000500015,-0.015152],
    [-4,-0.000500015,-0.015152],
    [-6,-0.000750023,-0.022728],
    [-6,-0.000750023,-0.022728],
    [-3,-0.000375011,-0.011364],
    [-5,-0.000625019,-0.01894],
    [-6,-0.000750023,-0.022728],
    [-5,-0.000625019,-0.01894],
    [-4,-0.000500015,-0.015152],
    [-5,-0.000625019,-0.01894],
    [-7,-0.000875027,-0.026516],
    [-3,-0.000375011,-0.011364],
    [-5,-0.000625019,-0.01894],
    [-4,-0.000500015,-0.015152],
    [-5,-0.000625019,-0.01894],
    [-6,-0.000750023,-0.022728],
    [-6,-0.000750023,-0.022728],
    [-5,-0.000625019,-0.01894],
    [-8,-0.00100003,-0.030304],
    [-6,-0.000750023,-0.022728],
    [-5,-0.000625019,-0.01894],
    [-7,-0.000875027,-0.026516],
    [-4,-0.000500015,-0.015152],
    [-6,-0.000750023,-0.022728],
    [-4,-0.000500015,-0.015152],
    [-5,-0.000625019,-0.01894],
    [-4,-0.000500015,-0.015152],
    [-7,-0.000875027,-0.026516],
    [-6,-0.000750023,-0.022728],
    [-4,-0.000500015,-0.015152],
    [-5,-0.000625019,-0.01894],
    [-6,-0.000750023,-0.022728],
    [-7,-0.000875027,-0.026516],
    [-6,-0.000750023,-0.022728],
    [-4,-0.000500015,-0.015152],
    [-6,-0.000750023,-0.022728],
    [-4,-0.000500015,-0.015152],
    [-8,-0.00100003,-0.030304],
    [-5,-0.000625019,-0.01894],
    [-6,-0.000750023,-0.022728],
    [-5,-0.000625019,-0.01894],
    [-4,-0.000500015,-0.015152],
    [-6,-0.000750023,-0.022728],
    [-4,-0.000500015,-0.015152],
    [-5,-0.000625019,-0.01894],
    [-6,-0.000750023,-0.022728],
    [-6,-0.000750023,-0.022728],
    [-8,-0.00100003,-0.030304],
    [-5,-0.000625019,-0.01894],
    [-4,-0.000500015,-0.015152],
    [-6,-0.000750023,-0.022728],
    [-6,-0.000750023,-0.022728],
    [-3,-0.000375011,-0.011364],
    [-4,-0.000500015,-0.015152],
    [-6,-0.000750023,-0.022728],
    [-5,-0.000625019,-0.01894],
    [-5,-0.000625019,-0.01894],
    [-4,-0.000500015,-0.015152],
    [-6,-0.000750023,-0.022728],
    [-3,-0.000375011,-0.011364],
    [-4,-0.000500015,-0.015152],
    [-6,-0.000750023,-0.022728],
    [-5,-0.000625019,-0.01894],
    [-7,-0.000875027,-0.026516],
    [-6,-0.000750023,-0.022728],
    [-4,-0.000500015,-0.015152],
    [-4,-0.000500015,-0.015152],
    [-5,-0.000625019,-0.01894],
    [-4,-0.000500015,-0.015152],
    [-7,-0.000875027,-0.026516],
    [-6,-0.000750023,-0.022728],
    [-4,-0.000500015,-0.015152],
    [-4,-0.000500015,-0.015152],
    [-5,-0.000625019,-0.01894],
    [-6,-0.000750023,-0.022728],
    [-5,-0.000625019,-0.01894],
    [-6,-0.000750023,-0.022728],
    [-5,-0.000625019,-0.01894],
    [-3,-0.000375011,-0.011364],
    [-6,-0.000750023,-0.022728],
    [-5,-0.000625019,-0.01894],
    [-6,-0.000750023,-0.022728],
    [-6,-0.000750023,-0.022728],
    [-5,-0.000625019,-0.01894],
    [-6,-0.000750023,-0.022728],
    [-6,-0.000750023,-0.022728],
    [-6,-0.000750023,-0.022728],
    [-6,-0.000750023,-0.022728],
    [-6,-0.000750023,-0.022728],
    [-5,-0.000625019,-0.01894],
    [-6,-0.000750023,-0.022728],
    [-7,-0.000875027,-0.026516],
    [-5,-0.000625019,-0.01894],
    [-4,-0.000500015,-0.015152],
    [-6,-0.000750023,-0.022728],
    [-6,-0.000750023,-0.022728],
    [-7,-0.000875027,-0.026516],
    [-8,-0.00100003,-0.030304],
    [-5,-0.000625019,-0.01894],
    [-7,-0.000875027,-0.026516]
])
# Datos de consumo correspondientes (Power)
y = np.array([
    -0.00348495,
    -0.00348495,
    -0.00522743,
    -0.00522743,
    -0.00261372,
    -0.00435619,
    -0.00522743,
    -0.00435619,
    -0.00348495,
    -0.00435619,
    -0.00609867,
    -0.00261372,
    -0.00435619,
    -0.00348495,
    -0.00435619,
    -0.00522743,
    -0.00522743,
    -0.00435619,
    -0.00696991,
    -0.00522743,
    -0.00435619,
    -0.00609867,
    -0.00348495,
    -0.00522743,
    -0.00348495,
    -0.00435619,
    -0.00348495,
    -0.00609867,
    -0.00522743,
    -0.00348495,
    -0.00435619,
    -0.00522743,
    -0.00609867,
    -0.00522743,
    -0.00348495,
    -0.00522743,
    -0.00348495,
    -0.00696991,
    -0.00435619,
    -0.00522743,
    -0.00435619,
    -0.00348495,
    -0.00522743,
    -0.00348495,
    -0.00435619,
    -0.00522743,
    -0.00522743,
    -0.00696991,
    -0.00435619,
    -0.00348495,
    -0.00522743,
    -0.00522743,
    -0.00261372,
    -0.00348495,
    -0.00522743,
    -0.00435619,
    -0.00435619,
    -0.00348495,
    -0.00522743,
    -0.00261372,
    -0.00348495,
    -0.00522743,
    -0.00435619,
    -0.00609867,
    -0.00522743,
    -0.00348495,
    -0.00348495,
    -0.00435619,
    -0.00348495,
    -0.00609867,
    -0.00522743,
    -0.00348495,
    -0.00348495,
    -0.00435619,
    -0.00522743,
    -0.00435619,
    -0.00522743,
    -0.00435619,
    -0.00261372,
    -0.00522743,
    -0.00435619,
    -0.00522743,
    -0.00522743,
    -0.00435619,
    -0.00522743,
    -0.00522743,
    -0.00522743,
    -0.00522743,
    -0.00522743,
    -0.00435619,
    -0.00522743,
    -0.00609867,
    -0.00435619,
    -0.00348495,
    -0.00522743,
    -0.00522743,
    -0.00609867,
    -0.00696991,
    -0.00435619,
    -0.00609867
])

# Crear y entrenar el modelo
model = LinearRegression()
model.fit(X, y)

# Hacer predicciones con el conjunto de datos de entrenamiento
y_pred = model.predict(X)

# Calcular MAE y MSE
mae = mean_absolute_error(y, y_pred)
mse = mean_squared_error(y, y_pred)
rmse = np.sqrt(mse)

# Calcular el margen de error en porcentaje
mae_percentage = (mae / np.mean(np.abs(y))) * 100

print(f"MAE: {mae}")
print(f"MSE: {mse}")
print(f"RMSE: {rmse}")
print(f"MAE Percentage: {mae_percentage}%")

# Predicción con nuevos datos
# Nuevos datos para predicción [ADC Value, Voltage, Current]
new_data = [[-5, -0.000625019,  -0.01894]]
prediction = model.predict(new_data)
print(f"Predicción para [15, 0.000375, 0.108120]: {prediction}")
